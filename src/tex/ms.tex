% Define document class
\documentclass[]{aastex631}
\usepackage{showyourwork}
% \usepackage{macros}
\usepackage{amsmath}

\newcommand{\Ho}{$H_0$}
\newcommand{\Omm}{$\Omega_M$}
\newcommand{\source}{\text{source}}
\newcommand{\diff}{\text{d}}

\newcommand{\plp}{\textsc{Power Law + Peak}}

\newcommand{\result}[1]{\textcolor{red}{#1}}
\newcommand{\comment}[1]{\textcolor{orange}{#1}}

% Begin!
\begin{document}

% Title
\title{Nonparametric Spectral Siren Cosmology}

% Author list
\author{@afarah18}

% Abstract with filler text
\begin{abstract}
    Lorem ipsum dolor sit amet, consectetuer adipiscing elit.
    Ut purus elit, vestibulum ut, placerat ac, adipiscing vitae, felis.
    Curabitur dictum gravida mauris, consectetuer id, vulputate a, magna.
    Donec vehicula augue eu neque, morbi tristique senectus et netus et.
    Mauris ut leo, cras viverra metus rhoncus sem, nulla et lectus vestibulum.
    Phasellus eu tellus sit amet tortor gravida placerat.
    Integer sapien est, iaculis in, pretium quis, viverra ac, nunc.
    Praesent eget sem vel leo ultrices bibendum.
    Aenean faucibus, morbi dolor nulla, malesuada eu, pulvinar at, mollis ac.
    Curabitur auctor semper nulla donec varius orci eget risus.
    Duis nibh mi, congue eu, accumsan eleifend, sagittis quis, diam.
    Duis eget orci sit amet orci dignissim rutrum.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Like light, gravitational waves (GWs) are redshifted as they propagate across the universe.
Unlike light, however, the selection effects of GWs are extremely well understood, allowing for a precise estimate of each catalogs' completeness and an unbiased measurement of the true GW population.
This allows GW signals to be used as relatively clean probes of cosmological parameters \citep[e.g.][]{bright sirens first paper, 170817 bright siren, dark siren first paper, dark siren with 0817, hithhikers guide}.

GW signals provide direct measurements of each source's luminosity distance and redshifted, or detector frame, masses, $m_{\det} = m_{\source}(1+z)$.
Therefore, if the source frame mass is known, each event provides a direct mapping between luminosity distance and redshift, allowing for a measurement of the rate of expansion of the universe at the time the GW signal was emitted, $H(z)$.
In practice, the source frame mass is unknown, but it is possible to know the location of features in the source frame mass distribution.
The whole mass distribution therefore acts similarly to an electromagnetic spectrum, where the location of spectral features provides a redshift measurement.
The method of using the mass distribution of GW sources to measure cosmological parameters has therefore been coined ``spectral sirens'' \citep{ezquiaga_spectral_2022}.
Spectral sirens were first demonstrated to be a feasible method to measure the Hubble constant by \cite{chernoff+fin} using the BNS mass distribution, and extended to the BBH mass distribution by \cite{farr_future_2019}.

Perhaps because of the analogy to electromagnetic spectra in which the location of the source frame spectral features is well-known, or because of the examples given in \cite{farr_future_2019} and \cite{chernoff+fin}, it is commonly presumed that the exact shape of the mass distribution must be known \emph{a priori} to do this measurement, from e.g. theoretical expectations of the location of a pulsational-pair instability pileup, upper mass gap, or maximum neutron star mass.
However, the information in the spectral siren measurement comes solely from the assumption that, at a given luminosity distance, all CBC mergers follow the same mass distribution.
Therefore the location, shape, and existence of all features in the mass distribution can be inferred simultaneously with $H(z)$.

In this work, we explicitly demonstrate that no \emph{a priori} knowledge about the shape of the CBC mass spectrum is necessary to use the spectral siren methodology by inferring \Ho with a non-parametric model for the mass distribution of CBCs. 
This flexible model makes minimal prior assumptions for the shape of the mass distribution and is therefore capable of accurately inferring a wide range of mass spectrum morphologies.
Despite its flexibility, it is able to consistently obtaining an unbiased measurement for \Ho, showing that nonparametric methods are not only sufficient for a spectral siren measurement, they can also mitigate systematic effects in the measurement caused by model misspecification.

\section{Motivating Example}
\comment{Maybe this should just be part of results. Like just do this for O5 data and show how bad it can be. if its not that bad, we can do it for even more events to show when it will be a problem.}

In this Section, we show that fitting an incorrect functional form to the mass distribution of CBCs biases the inference of cosmological parameters when using the spectral siren methodology.
To demonstrate this, we generate a catalog of \result{1,000} GW events from an underlying mass distribution described by the \plp{} model and its maximum \emph{a posteriori} hyperparameters from \citet{o3b_pop}.
We then use this catalog to infer \Ho{} using three different models for the source-frame mass distribution:
\begin{enumerate}
    \item the \plp{} model, which includes the true mass distribution within its hyperprior
    \item a single power law, which does not include the true mass distribution within its hyperprior, and 
    \item the flexible, Gaussian process-based model that we use for the remainder of this work, which can closely approximate the morphology of the true mass distribution, along with several other morphologies.
\end{enumerate}
The results of each of these fits are shown in Figure~\ref{fig:motivation}. 
The \result{top/left} panel shows the inferred source frame mass distribution for each of the considered models, and the \result{bottom/right} panel shows the corresponding posteriors on \Ho{}.

With \result{1,000} events, we find that using the incorrect parametric form of the mass distribution (a power law) causes a biased inferred value of \Ho{} at the \result{X}-$\sigma$ level, whereas using the correct functional form (\plp) provides an unbiased inference of \Ho.
However, this is not due to the need to know the morphology of the mass distribution \emph{a priori}, as the Gaussian process-based model recovers the correct value of \Ho{} despite making minimal assumptions about the mass distribution.
The Gaussian process-based model does, however, obtain larger uncertainties on the inferred value of \Ho, as it has many more free parameters.
We have repeated this analysis with \result{50} separate simulated catalogs, and found that the power law model causes us to infer a \result{higher/lower} value of \Ho{} at greater than \result{X}-$\sigma$, \result{Y}\% of the time, whereas the Gaussian process-based model reaches that level of bias only \result{Z}\% of the time, and the \plp{} model reaches the same level of bias \result{A}\% of the time.
This indicates that prior knowledge of the shape of the mass distribution is not required to perform a spectral siren measurement, so long as strong assumptions about the shape of the mass distribution are not made.

\begin{figure}
    \centering
    \includegraphics{figures/diff_mass_dists_example.pdf}
    \caption{Caption}
    \label{fig:motivation}
\end{figure}

\section{Methods}
\label{sec:methods}
\subsection{Data simulation}
We generate a mock catalog of GW events characteristic of that expected from the LVK's fifth observing run (O5). 
These events are drawn from an underlying population described by
\begin{equation}
\label{eq:underlying population}
    \frac{\diff N}{\diff m_1 \diff m_2 \diff z} \propto p(m_1, m_2|\bar{\Lambda}_m) p(z|H_0, \Omega_M),
\end{equation}
where 
\begin{align}
    p(m_1,m_2|\bar{\Lambda}_m) &\propto \\
    p(z|H_0, \Omega_M) &\propto \frac{\diff V_C}{\diff z} \frac{1}{1+z},
\label{eq:underlying mass and redshift dist}
\end{align}
, $V_C(H_0, \Omega_M)$ is the comoving volume for given cosmological parameters \Ho{} and \Omm{}, and $\bar{\Lambda_m} = \alpha$... are the parameters describing the power law in primary mass, ... respectively. 
When generating the simulated events, we have fixed $\alpha= $... and used cosmological parameters \Ho$=68.7$, \Omm$=0.3$, $\Omega_\Lambda=1-\Omega_M$.
These choices correspond to the maximum \emph{a posteriori} values obtained by an analysis of GWTC-3 data using the \_ model \cite{o3b_pop}, which is morphologically similar to that described in Equations~\ref{eq:underlying population}--\ref{eq:underlying mass and redshift dist}.
We neglect spins entirely, as they do not carry cosmological information.
\comment{TODO: fill in details of mass distribuiton. Should we use PDB and include BNSs, which will give us a nice sharp feature to work with, or should we use PLP which has a bump? Could also do PLP and then put a uniform dist or power law for NS masses at the LMG, and leave an empty mass gap. Would need to get relative heights correct though.}

After passing the simulated events through projected detector selection effects, the resulting catalog has \result{X} events, including \result{X} binary neutron star systems, \result{Y} NSBH systems, and \result{Z} BBH systems, consistent with the numbers projected for O5 by \citet{kiendrebogo_observing_2023}.
We use the software package \texttt{GWMockCat} \citep{farah_things_2023} to simulate posterior samples for these events with measurement uncertainties typical of those expected from O5 detectors.
\texttt{GWMockCat} also simulates a set of software injections, which we use to estimate selection effects in the inference.
To determine the detectability of both injections and simulated events in O5, we use the projected O5 LIGO power spectral density \citep{dcc page} to calculate observed signal-to-noise ratios $\rho_{\text{obs}}$, and we consider events and injections with $\rho_{\text{obs}}>8$ to be detectable. 
The full procedure for this mock data generation process is described in \citet{fishbach_where, farah_things_2023, essick_dagnabbit_2023}, and the exact settings used for \texttt{GWMockCat} are made available in the accompanying data release. \comment{TODO:put a showyourwork link here.}

\subsection{Spectral sirens and statistical framework}
\label{sec:ss}
\begin{enumerate}
    \item Briefly explain HBA with selection effects.
\end{enumerate}
\begin{equation}
    p(\Lambda|data) = p(\Lambda)\exp{-Nexp} \Pi L_i
    \label{eq:inhomog-poisson}
\end{equation}
We infer this posterior using the no-u-turn sampler for Hamiltonian Monte Carlo within `numpyro` \citep{hoffman_no-u-turn_2011, numpyro}. 

The spectral siren method of measuring cosmological parameters relies on the assumption that all compact binaries follow the same mass distribution, regardless of redshift, or if the mass distribution evolves with redshift in any way besides a monotonic rightwards shift.
The likelihood in Equation~\ref{eq:inhomog-poisson} is maximized when the relationship between redshift and luminosity distance makes all source frame masses to follow the same distribution\footnote{\citet{ezquiaga_spectral_2022} show that the source frame masses can follow different distributions at different redshifts, so long as this redshift evolution of the mass distribution does not exactly mimic cosmology (i.e. all features cannot exhibit a monotonic rightward shift with redshift).}.
This is the basis of the spectral siren method of measuring cosmological parameters; we can simultaneously infer the relationship between redshift and luminosity distance with the parameters of the source frame mass distribution.
The full set of hyper-parameters therefore includes the cosmological parameters that dictate the $D_L$-$z$ relation: \Ho, \Omm, $\Omega_\Lambda, \Omega_r,$ and $w$.
In this work, we fix $\Omega_\Lambda=1-\Omega_M, \Omega_r=0$ and $w=1$ and use uniform priors on \Ho{} and \Omm{}.
Algorithmically, this is equivalent to drawing a value of \Ho, using it to define a relationship between luminosity distance and redshift, then transforming detector frame masses to source frame masses according to $m_{\det} (1+z(D_L)) = m_{\text{source}}$, evaluating the source-frame mass distribution at these transformed values, and then evaluating the likelihood in Equation~\ref{eq:inhomog-poisson}.
The full process is outlined in Section~\ref{sec:model}.


\subsection{Gaussian process-based mass distribution}
\label{sec:model}
Gaussian processes (GPs) are random processes for which any linear combination of outcomes are Gaussian distributed \citep{rasmussen_gaussian_2006}.
Their smoothness properties make them widely useful in GW data analysis and beyond for regression problems, such as modeling time-domain waveforms \citep{zoheyr, huerta}, density estimation problems, such as estimating posterior densities of single-event parameters from parameter estimation samples ~\citep{dangelo}, and as a prior on histogram bin heights \citep{ray_2023,li_flexible_2021}.
Our use case is slightly different.
We will utilize a GP as a prior on the functions that describe the primary mass distribution of CBCs.
This choice adds very little prior information about the shape of the mass distribution, besides enforcing that it must be smooth.
Practically, the only difference in the inference of the population when using a GP versus other modeling choices is that $p(m_1|\Lambda)$ in Equation~\ref{eq:inhomog-poisson} is determined directly by a realization of the GP, rather than by a handful of hyper-parameters $\Lambda$ and evaluated on an analytical function.

In other words, when using parametric models, $p(\theta|\Lambda)$ in Equation~\ref{eq:} is calculated by evaluating a specific functional form described by a small set of hyper-parameters, $\Lambda$. 
With the GP approach, the hyper-parameters describing the mass distribution are the rate at each event-level posterior sample's source frame mass, and the rate at each found injection's source frame mass.
% The source frame mass is different for each possible value of \Ho{} and \Omm{}, so the hyper-parameters are defined in different locations for each draw from the hyper-posterior.
We therefore have $N_{\text{evs}}M + N_{\text{inj}}$ mass hyper-parameters, where $N_{\text{ev}}$ is the number of events, $M$ is the number of PE samples per event, and $N_{\text{inj}}$ is the number of injections used to calculate the selection function $\xi$.
We label these $\{\mathcal{R}_ij,\mathcal{R}_k\}$, and our full set of hyper-parameters is $\Lambda=\{\H_0, \Omega_M, \mathcal{R}_ij,\mathcal{R}_k\}$. 
In this way, our GP-based mass distribution is similar to the autoregressive population models used in ~\citet{callister_ar}.
Indeed, an autoregressive model is a Gaussian process with a particular choice of kernel.

A kernel is a function that defines the covariance between input points in the GP (in our case, two source frame mass values). 
It defines the notion of similarity between adjacent points and thereby encodes our assumptions about the smoothness of the source frame mass distribution \citep{rasmussen_gaussian_2006}.
We use a Mat\'ern kernel \citep{handcock_and_stein,stein_1999} with $\nu = 5/2$, but have repeated the analysis with $\nu=3/2$ and $\infty$, finding little impact on the results, except that the $\nu=\infty$ case (also called the ``squared exponential'' kernel) produces a slightly more jagged mass distribution.
Mat\'ern kernels have two parameters besides the mean variance that determine their properties: a length scale $l$ and variance $s$.
In our use case, these are one level further removed from hyper-parameters, so we adopt the terminology used in \citet{callister_ar} and call them ``hyper-hyper-parameters.''
We fit these hyper-hyper-parameters along with the hyper-parameters $\Lambda$ to minimize prior assumptions about the form of the mass distribution.
We use ``penalized-complexity'' priors on the hyper-hyper-parameters to enforce that the model does not create small-scale structure uninformed by data, thereby avoiding over-fitting \citep{simpson_penalising_2017,simpson_garcpas_2022}. % remove this if we don't use it.
Explicitly, the priors on $l$ and $s$ have less than 5\% support for correlation lengths smaller than the \result{minimum} spacing between event-level posterior samples.

GP evaluations notoriously scale as the cube of the number of data points, making them unwieldy with large data sets such as the ones expected for O5.
We therefore make two approximations to a full GP to increase computational efficiency.
First, for each likelihood evaluation, we evaluate a full GP on a regular grid between $0\Msun$ and $250\Msun$ and then interpolate it at each data point.
Second, we use the quasi-separability of Mat\'ern kernels to analytically perform the transformation between covariance matrix and GP draw.
This second step is done using the \texttt{QuasisepSolver} module \citep{foreman-mackey_fast_2017} in the \texttt{tinygp} code base, and requires data to be sort-able (i.e. one-dimensional).

Algorithmically, each hyper-likelihood evaluation contains the following steps:
\begin{enumerate}
    \item Draw cosmological parameters \Ho{} and \Omm{} from the prior distributions described in Equation~\ref{eq:cosmo-priors}.
    \item Transform the luminosity distances and detector frame masses of each event posterior sample and injection into redshifts and source frame masses according to the cosmology specified by step 1.
    \item Draw hyper-hyper-parameters $l$ and $s$ from the penalized-complexity priors described above.
    \item Draw a single GP realization with a kernel defined by $l$ and $s$. This is defined on a regular grid of source-frame masses and evaluated using the \texttt{QuasisepSolver}.
    \item Interpolate the GP at each event posterior sample and injection source frame mass (from step 2)
    \item Calculate the population likelihood according to Equation~\ref{eq:inhomog-poisson}.
\end{enumerate}

\section{Results}
\label{sec:results}
We fit the non-parametric population model described in Section~\ref{sec:model} to a simulated GW catalog of \result{1,000} GW events from an underlying mass distribution described by the \plp{} model and its maximum \emph{a posteriori} hyperparameters from \citet{o3b_pop}.

The resulting inferred mass distribution is shown in Figure~\ref{fig:O5_GP}, along with the corresponding posterior on \Ho.
The inferred mass distribution (left panel) closely resembles the true, simulated distribution, and the injected value of \Ho is consistent with its inferred posterior distribution (right panel).
Additionally, the posterior on \Ho is distinct from its prior distribution, indicating that the data is informative despite the flexibility of the population model.
This measurement represents 

We repeat this analysis with two parametric models: the \plp{} model, which includes the true mass distribution within its hyperprior, as well as a single power law, which does not include the true mass distribution within its hyperprior.
The results of each of these fits is shown in Figure~\ref{fig:O5_parametric}, and their performance is summarized in Table~\ref{tab:bias}.
When using a parametric model of the same form as the true simulated distribution (\plp), we recover the injected value of \Ho{} within \result{X-$\sigma$}.
However, when using a model that cannot accurately represent the true shape of the mass distribution, we recover a biased estimate of \Ho: the true value is offset from the mean of the posterior by \result{X}-$\sigma$.

\begin{figure}
    \centering
    \includegraphics{figures/O5_GP.pdf}
    \caption{Two-panel figure of mass distribution and \Ho{} posterior. If we end up fitting \Omm{} we can put a corner plot instead.}
    \label{fig:O5_GP}
    \script{nonparametric_plots.py}
\end{figure}

\begin{figure}
    \centering
    \includegraphics{figures/O5_parametric.pdf}
    \caption{Same as Figure~\ref{fig:O5_GP} but for parametric models. We can probably combine these two figures.}
    \label{fig:O5_parametric}
\end{figure}

\begin{table}[]
    \centering
    \begin{tabular}{c|c c}
         Model & $\sigma_{H_0}$ [km/s/Mpc] & bias [km/s/Mpc]\\
         \hline
         & 
    \end{tabular}
    \caption{Performance of various mass distribution models used for measuring the Hubble constant, \Ho.
    We consider the correct parametric model, an incorrect parametric model, and the non-parametric, Gaussian process-based model presented in this work.
    Bias is defined as the number of standard deviations between the true injected value of \Ho and the recovered posterior mean. 
    The parametric models yield more precise constraints on \Ho{}, as shown by smaller standard deviations ($\sigma_{H_0}$), but the incorrect parametric model is less accurate than the non-parametric model.
    In reality, it is impossible to know the true functional form of the mass distribution, so the additional statistical uncertainty introduced by non-parametric approaches may be desirable over the systematic errors associated with choosing a parametric model.
    }
    \label{tab:bias}
\end{table}

\begin{itemize}
    \item Can get constraints on \Ho{} to X\% by the end of O5
    \item If possible, could do constraints on H0 as a function of \# of events.
    \item could also plot H(z) using posterior draws from \Ho{} and \Omm{}- can see at which redshift you get the best constraints. Then plot posterior of $H(z=z_{\text{best measured}})$ rather than \Ho
\end{itemize}
\section{Discussion}
\label{sec:discussion}


\begin{itemize}
    \item We are able to get constraints on comsological parameters with a very flexible model for the mass distribution. 
    \item The true population of compact objects in the Universe is unknown, so we will never have access to a measurement of \Ho{} made with a model of the same form as the true mass distribution when using real data.
Systematic uncertainties arising from an incorrect choice for the functional form of the mass distribution are therefore inevitable.
With current detectors, these systematic effects are dwarfed by statistical uncertainties.
However, next-generation detectors will herald in enough GW observations to substantially decrease statistical uncertainty in these measurements.
Non-parametric approaches such as the ones presented here will aid in mitigating systematic effects.
    \item hopefully these will be less biased than using a parametric model
    \item Also, this shows that you don't need to know the shape of the mass distribution a priori to do spectral sirens.
    \item This is because the information in spectral sirens comes from assuming events come from the same overall mass distribution across redshift, and that mass distribution doesn't evolve with redshift in the same exact way as would be mimicked by cosmological redshifting. This assumption is very basic, not an assumption that we know the exact astrophyisics of BBH formation (i.e. PPISN feature location)
    \item future/in prep. work will do the same thing but for a mass distribution that is allowed to evolve with redshift, similarly to the parametric analysis done in~\cite{ezquiaga_spectral_2022}, but with the evolution with redshift allowed to be arbitrary so long as it does not mimic cosmology. - GPs are good bc they can do correlations/generalize to multiple dimensions naturally. Our choice of kernel allows us to do this, but its not possible with the autoregressive kernel.
\end{itemize}
\begin{acknowledgments}
    The authors thank Reed Essick, Utkarsh Mali, Ben Farr, Maya Fishbach,  for helpful conversations.
\end{acknowledgments}

\bibliography{bib}
\appendix
\section{Details of data simulation}

\end{document}
