% Define document class
\documentclass[preprint2,linenumbers]{aastex631}
\usepackage{showyourwork}
\usepackage{macros}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{acro}
\acsetup{patch/longtable=false}

\DeclareAcronym{LVK}{short=LVK, long=LIGO-Virgo-KAGRA}
\DeclareAcronym{O5}{short=O5, long=the fifth LIGO-Virgo-KAGRA observing run}

\DeclareAcronym{GW}{short=GW, long=gravitational wave}
\DeclareAcronym{CBC}{short=CBC, long=compact binary coalescence}
\DeclareAcronym{BBH}{short=BBH, long=binary black hole}

\DeclareAcronym{GP}{short=GP, long=Gaussian process, long-plural=es}

% Begin!
\begin{document}

% Title
\title{No need to know: astrophysics-free gravitational-wave cosmology}
% Daniel : No need to know: gravitational-wave cosmology without astrophysics [I like this one better than the top one, since it's catchier/more direct, and will get more attention; but are people worried it's too strong?]}
% Amanda: I put it to a poll and the current one got more votes! No one gave a reason as to why, though
% Daniel: okay, FWIW i just asked a professional writer, and she votes for the 2nd one: "astrophysics-free GW cosmo". 'I think the "astrophysics-free" is very sugarfree funny, and matches the No Need to Know wit well.'
% Amanda: I like astrophysics-free! That wasn't in the poll I sent yesterday so I  will just take the liberty to assume that others are okay with it as well :p

% Other ideas:
% No need to know: gravitational-wave cosmology without astrophysical assumptions
% No need to know: gravitational-wave cosmology for the astrophysically-ignorant

% Author list
%\author{@afarah18}
\author[0000-0002-6121-0285]{Amanda M. Farah}
\email{afarah@uchicago.edu}
\affiliation{Department of Physics, University of Chicago, Chicago, IL 60637, USA}

\author{Thomas A. Callister}
\affiliation{Kavli Institute for Cosmological Physics, The University of Chicago, Chicago, IL 60637, USA}

\author[0000-0002-7213-3211]{Jose Mar\'ia Ezquiaga}
%\email{jose.ezquiaga@nbi.ku.dk}
\affiliation{Niels Bohr International Academy, Niels Bohr Institute, Blegdamsvej 17, DK-2100 Copenhagen, Denmark}

\author[0000-0002-0147-0835]{Michael Zevin}
\affiliation{The Adler Planetarium, 1300 South DuSable Lake Shore Drive, Chicago, 60605, IL, USA}

\author{Daniel E. Holz}
\affiliation{Department of Physics, University of Chicago, Chicago, IL 60637, USA}
\affiliation{Kavli Institute for Cosmological Physics, The University of Chicago, Chicago, IL 60637, USA}
\affiliation{Department of Astronomy \& Astrophysics, The University of Chicago, Chicago, IL 60637, USA}
\affiliation{Enrico Fermi Institute, The University of Chicago, Chicago, IL 60637, USA}


% Abstract
\begin{abstract}
\Acp{GW} from merging compact objects encode direct information about the luminosity distance to the binary. 
When paired with a redshift measurement, this enables standard-siren cosmology: a Hubble diagram can be constructed to directly probe the Universe's expansion.
This can be done in the absence of electromagnetic measurements, as features in the mass distribution of \ac{GW} sources provide self-calibrating redshift measurements without the need for a definite (bright siren) or probabilistic (dark siren) host galaxy association. 
This ``spectral siren'' technique has thus far only been applied with simple parametric representations of the mass distribution. 
However, the use of an inaccurate representation leads to biases in the cosmological inference, an acute problem given the current uncertainties in true source population.
Furthermore, it is commonly presumed that the form of the mass distribution must be known \emph{a priori}\/ to obtain unbiased measurements of cosmological parameters in this fashion.
Here, we demonstrate that spectral sirens can accurately infer cosmological parameters without such prior assumptions.
We apply a flexible, non-parametric model for the mass distribution of compact binaries to a simulated catalog of 1,000 \ac{GW} signals, consistent with expectations for the next \acl{LVK} observing run.
We find that, despite our model's flexibility, both the source mass model and cosmological parameters are correctly reconstructed.
We predict a $\variable{output/nonparh0percent.txt}\%$ measurement of \Ho{}, keeping all other cosmological parameters fixed, and a $\variable{output/Hz_percent.txt}\%$  measurement of $H(z=\variable{output/mostsensitivez.txt})$ when fitting for multiple cosmological parameters ($1\sigma$ uncertainties).
This astrophysically-agnostic spectral siren technique will be essential to arrive at precise and unbiased cosmological constraints from \ac{GW} source populations.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Like light, \acp{GW} are redshifted as they propagate across the universe, thereby bearing imprints of the Universe's cosmic expansion history.
Unlike light, however, the form of \ac{GW} signals are known from first principles, directly from the theory of general relativity. Furthermore, because \acp{GW} propagate across the Universe without attenuation from intervening matter, and because the properties of \ac{GW} detectors are well characterized, \ac{GW} selection effects are extremely well understood. % This is to be contrasted with many electromagnetic observations, where effects such as reddening, selection bias, and $k$-corrections can lead to significant complications. [too strong?]
This allows for a precise estimate of each \ac{GW} catalogs' completeness and an unbiased measurement of the true \ac{GW} source population~\citep{2023PhRvX..13d1039A,abbott_population_2023,2023PhRvD.108d3011E}. 
Additionally, the \ac{GW} signals observed by the LIGO, Virgo, and KAGRA detectors~\citep{aasi_advanced_2015,acernese_advanced_2014,akutsu_overview_2021}  provide direct measurements of the distance to their sources.
This makes them ``standard sirens'': direct probes of cosmological parameters that circumvent the need for a cosmological distance ladder~\citep{schutz_determining_1986,holz_using_2005}. 

A well-known demonstration of standard siren cosmology was the multi-messenger event GW170817 \citep{abbott_multi-messenger_2017,coulter_swope_2017,valenti_discovery_2017,2017ApJ...848L..27T}, whose clear association with a host galaxy provided a precise redshift measurement and allowed for a direct ``bright siren'' measurement of the Hubble constant, \Ho{} \citep{abbott_gravitational-wave_2017}.
External redshift information can also come from galaxy catalogs, which provide an ensemble of possible redshifts for each \ac{GW} signal, allowing for a probabilistic ``dark siren'' measurement of \Ho{} when multiple \ac{GW} detections are combined \citep{del_pozzo_inference_2012, chen_two_2018, fishbach_standard_2019, soares-santos_first_2019,gray_cosmological_2020, abbott_gravitational-wave_2021, gwtc3_cosmo, gray_pixelated_2022,gray_joint_2023,mastrogiovanni_joint_2023, gair_hitchhikers_2023}.

Electromagnetic information about \ac{GW} source redshifts need not be available in order to use them as standard sirens, however.
\ac{GW} signals provide direct measurements of each source's luminosity distance, $d_L$, and redshifted (detector frame), masses, $m_{\det}= m_{\source}(1+z)$ \citep[e.g.][]{chen_mass-redshift_2019}.
Therefore, if the source frame mass is known, each \ac{GW} signal provides a direct mapping between luminosity distance and redshift, allowing for a measurement of the expansion of the universe at the time the \ac{GW} signal was emitted, $H(z)$.
\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/O5_pm.pdf}
    \caption{Spectral siren measurement for a simulated catalog with the correct parametric model (\plp, green), a deliberately incorrect parametric model (broken power law, orange) and the non-parametric model presented in this work (\acl{GP}, blue).
    The left panel shows the recovered source frame primary mass distribution for each model, and the simultaneously-inferred posteriors on \Ho{} are shown in the right panel.
    The mass distribution and \Ho{} value used to generate the data are shown by a solid black line in each panel. 
    The deliberately incorrect parametric model fails to recover the true mass distribution and therefore produces an estimate of \Ho{} that is offset from the true value, whereas both the correct and non-parametric models recover the mass distribution and \Ho{}.
    As the true mass distribution is unknown for real observations, using a non-parametric model mitigates systematic uncertainty that would otherwise arise from mismodeling the \ac{CBC} population.
    }
    \label{fig:O5_GP}
    \script{pm_H0_twopanel.py}
\end{figure*}

In practice, the source-frame masses of individual \ac{GW} signals are not known~\citep[unless tidal information is available, e.g.][]{messenger_measuring_2012, 2021PhRvD.104h3528C}.
It is, however, possible to consider the \textit{population} of compact binaries at large and use known features in their source-frame mass distribution to obtain self-calibrated redshift estimates.
The full mass distribution therefore acts analogously to an electromagnetic spectrum, in which the apparent locations of spectral features relative to their rest-frame locations provide a redshift measurement.
The method of using the mass distribution of \ac{GW} sources to measure cosmological parameters has therefore been coined ``spectral sirens'' \citep{ezquiaga_spectral_2022}.
Spectral sirens were first demonstrated to be a feasible method to measure the Hubble constant by \cite{chernoff_gravitational_1993} and \cite{Taylor:2011fs} using the binary neutron star mass distribution, and extended to the \ac{BBH} mass distribution by \cite{farr_future_2019}. 
Spectral siren analyses have since been implemented by the LIGO--Virgo--KAGRA Collaborations using the latest \ac{GW} catalog \citep{gwtc3_cosmo}.

Central to the spectral siren methodology is knowledge of the compact binary mass distribution.
However, first principles models for mass distributions of merging compact binaries are not available: significant theoretical uncertainties exist about the shapes, locations, and very existence of predicted features in the mass distribution~\citep[e.g.][]{ zevin_constraining_2017, mapelli_binary_2020,2021ApJ...910..152Z,marchant_evolution_2023}.
This includes uncertainties about potentially dominant features, such as the existence of a ``pile-up'' due to pulsational-pair instability, a pair-instability-driven upper mass gap~\citep{farmer}, the maximum neutron star mass~\citep{fryer_theoretical_2001, alsing_evidence_2018}, and the existence of a putative lower mass gap between neutron stars and black holes~\citep{ozel_black_2010, farr_mass_2011, farah_bridging_2022}.
To this end, spectral siren cosmology relies on \textit{simultaneously} measuring a source-frame mass spectrum alongside cosmological parameters.
This is typically accomplished by adopting a phenomenological, parametric model for the mass distribution, usually composed of power laws and Gaussians \citep[e.g.][]{gwtc3_cosmo,mastrogiovanni_icarogw_2023}.

Such parametric modeling of the compact binary mass distribution raises its own set of dangers.
It is well known that different parametric models can generically yield very different constraints on cosmological parameters ~\citep{abbott_population_2021,abbott_population_2023}.
This is problematic: because the measured mass distribution serves as the template by which to extract redshifts, a mismodeled mass distribution would introduce systematic errors in inferred redshifts and, in turn, systematically bias any resulting cosmological inference~\citep{ezquiaga_spectral_2022,Mukherjee:2021rtw,mastrogiovanni_importance_2021,pierra_study_2023}.

The situation is demonstrated in Fig.~\ref{fig:O5_GP}, in which we perform spectral siren cosmology on a simulated population of binary black holes.
We reconstruct the mass distribution using two parametric models, one that contains the true simulated mass distribution and one that does not.
While the former yields a measurement of $H_0$ consistent with the true underlying value, the latter does not.
Such systematic biases may already be relevant, as cosmological measurements by the LIGO-Virgo-KAGRA are known to depend on the choice of mass model used~\citep{gwtc3_cosmo}.
Furthermore, these biases may become a dominant source of uncertainty in the near future~\citep{pierra_study_2023}.
The prospects of such a dominant systematic uncertainty is troubling.
If prior knowledge of the mass distribution's morphology (whether an exact theoretical prediction or knowledge of the correct parametric family of models) is a prerequisite for the spectral siren method, the effectiveness of such a technique would be significantly hampered.

In this work, we explicitly demonstrate that no prior knowledge of the shape of the \ac{CBC} mass spectrum is necessary to use the spectral siren methodology. 
We do this by inferring $H(z)$ with a flexible, non-parametric model for the mass distribution of \acp{CBC} (blue lines in Figure~\ref{fig:O5_GP}). 
This model makes minimal prior assumptions about the shape of the mass distribution, enabling it to accurately infer a wide range of morphologies and remain agnostic to the astrophysical processes that give rise to features in the mass distribution.
Despite its flexibility, our approach is able to consistently obtain unbiased measurements of cosmological parameters, showing that nonparametric methods are not only sufficient for a spectral siren measurement, they can also mitigate systematic effects in the measurement caused by model misspecification.
The success of the non-parametric mass model in recovering the injected cosmological parameters demonstrates that the information in the spectral siren measurement does not come from the enforcement of specific features in the mass distribution.
Rather, it is provided by the assumption that either all \acp{CBC} follow a common mass distribution, or that any evolution of the mass distribution with redshift does not exactly mimic cosmology \citep{ezquiaga_spectral_2022}.

We find that our non-parametric model allows for a $\variable{output/nonparh0percent.txt}\%$ measurement of \Ho{} and a $\variable{output/Hz_percent.txt}\%$ measurement of $H(z=\variable{output/mostsensitivez.txt})$ during \ac{O5}, when the detectors will reach their design sensitivity. %, and a \result{X}\% measurement with only \result{X} weeks of observing with a next-generation detector network. 
We highlight measurements of \Ho{} in order to benchmark the accuracy and precision of our non-parametric method, as well as explore the role of spectral sirens in elucidating the Hubble tension.
However, the primary utility of spectral siren measurements will be in constraining $H(z)$ at redshifts that are relatively inaccessible by electromagnetic observations, especially with next-generation gravitational-wave detectors \citep{ezquiaga_spectral_2022, Chen:2024gdn, You:2020wju}.\footnote{See example spectral siren cosmological inference using parametric mass spectrum models: \href{https://github.com/ezquiaga/spectral_sirens}{https://github.com/ezquiaga/spectral\_sirens}.}
When applied to data from next-generation detectors, this method will measure the dark energy equation of state parameter, $w$, at redshifts $\gtrsim 2$.

This paper is organized as follows: Section~\ref{sec:data generation} describes the simulated dataset.
Section~\ref{sec:ss} introduces the spectral siren method, demonstrating how cosmological parameters are inferred from the mass distribution of \ac{GW} sources.
Section~\ref{sec:model} describes the non-parametric mass distribution we develop for use within the spectral siren method.
In Section~\ref{sec:results}, we present the results of using parametric and non-parametric mass distributions, as well as projections for future constraints on $H(z)$.
We discuss the implications of our results and outline future work in Section~\ref{sec:discussion}.

The code used to generate all simulated data, perform the population inference, and create all figures in this paper is made publicly available at \url{https://github.com/afarah18/spectral-sirens-with-GPs}. %\GitHubURL{}, and was enabled by the \showyourwork package \citep{Luger2021}.

\section{Cosmology with an astrophysically-agnostic mass model}
\label{sec:methods}

The spectral siren method of measuring cosmological parameters relies on the assumption that either all compact binaries follow the same mass distribution at all redshifts, or that any redshift evolution of the mass distribution does not perfectly mimic cosmology \citep[i.e. all features do not simultaneously exhibit an {\em identical}\/ monotonic rightward shift with redshift;][]{ezquiaga_spectral_2022}.
Specifically, the method identifies the preferred relationship between luminosity distance and redshift that causes all masses to follow this common source-frame distribution.
We do not need to know this source-frame distribution in advance, but, given some model for the black hole mass distribution, can infer it simultaneously with the cosmological expansion.

As described above, though, strongly parametrized models for the mass distribution yield biased measurements of cosmological parameters if they poorly approximate the true mass distribution of compact binaries.
We aim to circumvent such biases and instead model the population of \acp{GW} sources in a flexible and astrophysically-agnostic way. 
There exist several non-parametric methods developed for this purpose \citep{tiwari_vamana_2021,edelman_aint_2022,sadiq_flexible_2022,rinaldi_hdpgmm_2022,edelman_cover_2023,mandel_extracting_2019,ray_non-parametric_2023}.
While well-suited to infer the \ac{GW} source population with a fixed cosmology, several of these methods employ fixed features in source frame mass, such as bin edges \citep{mandel_extracting_2019,ray_non-parametric_2023} or spline nodes \citep{edelman_aint_2022}.
Since these locations were chosen with a fixed cosmology, they risk causing the inference to prefer the cosmological parameters assumed when choosing the feature locations. 
Indeed, \citet{mastrogiovanni_importance_2021} show how using fixed features can significantly bias cosmological inference within the spectral siren methodology.
We therefore opt for a model of the source frame mass distribution that foregoes the need to define such features.

% Intro to GPs
For this purpose, we construct a model with a \acf{GP}, a common tool for non-parametric inference. 
\Acp{GP} are random processes for which any linear combination of outcomes are Gaussian distributed \citep{rasmussen_gaussian_2006}.
Their smoothness properties make them widely useful in \ac{GW} data analysis for regression problems, such as modeling time-domain waveforms \citep{doctor_statistical_2017, huerta_eccentric_2018} and the neutron star equation of state \citep{landry_nonparametric_2019}, density estimation problems, such as estimating posterior densities of single-event parameters from parameter estimation samples ~\citep{demilio_density_2021}, and as a prior on histogram bin heights for population inference \citep{mandel_model-independent_2017, li_flexible_2021, ray_non-parametric_2023}.

Our use case is slightly different from previous analyses:
we utilize a \ac{GP} as a prior on the functions that describe the primary mass distribution of \acp{CBC}.
This choice adds very little prior information about the shape of the mass distribution, besides enforcing that it must be smooth.

\subsection{Simulated Data}
\label{sec:data generation}
%% TRANSITION: Describe how our goal is to demonstrate the utility of GPs and cosmology by constructing and analyzing a simulated catalog. 
To demonstrate the effectiveness of our \ac{GP}-based mass distribution in inferring both cosmological parameters and the population of \ac{GW} sources without introducing features or biases driven by prior assumptions, we apply our methodology to a simulated dataset.
By generating a catalog of \ac{GW} sources from a known population and cosmological model, we are able to quantify the accuracy of our method.
The use of simulated data also enables us to make projections for future datasets and safely ignore dimensions such as spin and mass ratio that do not impact cosmological measurements but would otherwise be important to simultaneously fit to avoid biases in population inference of real data~\citep{biscoveanu_sources_2021}.

%% Describe details of catalog
We design our simulated catalog to match the characteristics of the data expected from one year of observation in \ac{O5}. 
The \acp{BBH} in this catalog are drawn from an underlying population described by the \plp{} mass distribution presented in \citet{talbot_measuring_2018} and used in \citet{abbott_binary_2019, abbott_population_2023}, as well and the redshift distribution presented in \citet{callister_shouts_2020}, with hyperparameters consistent with those found in \citet{abbott_population_2023}.
We assume the mass distribution has no redshift evolution for the redshift range to which the \ac{O5} detectors will be sensitive. 
This assumption is consistent with current data \citep{fishbach_when_2021,van_son_redshift_2022,abbott_population_2023}, but will have to be revisited in future observing runs.
If we had constructed a catalog with an evolving mass distribution, we would have needed to correspondingly allow for redshift evolution in our population inference.
We leave a full treatment of redshift evolution for future work, as discussed in Section~\ref{sec:discussion}.
We use the \texttt{GWMockCat}~ \citep{farah_things_2023} package to apply \ac{O5}-like selection effects to the drawn \acp{BBH}, generate realistic measurement uncertainty, and produce sensitivity estimates that are consistent with the simulated \ac{GW} signals.
We will use the term ``event'' to refer to \ac{GW} signals that pass the criteria for detection.
This process results in a catalog of $N_{\text{ev}} = \variable{output/num_found_events.txt}$ \ac{GW} signals that pass the criteria for detection, hereon called events.


Additional details of the data simulation, including the form of the injected population, are described in Appendix~\ref{ap:data generation}. 

%% Go into the details of the likelihoods needed for the data analysis - new subsection?
\subsection{The Spectral Siren Method}
\label{sec:ss}
To simultaneously infer cosmological parameters and the population of \ac{GW} sources, we employ a hierarchical Bayesian analysis.
This allows us to undo the selection effects of \ac{GW} detectors to obtain a true, astrophysical population and constrain the cosmic expansion history.

Given a source population and background cosmology described by hyperparameters $\Lambda$, the likelihood of observing data $\{d\}$ that contains $N_{\text{ev}}$ detected \ac{GW} signals, each with parameters $\theta_i$, is \citep{loredo_handling_2009, Taylor:2011fs, mandel_extracting_2019,vitale_inferring_2020}
\begin{equation}
\begin{aligned}
    &p(\{d\},\{\theta\}|\Lambda) \propto \\
    &\hspace{1.2cm} e^{-N_{\text{exp}}(\Lambda)}\prod_i^{N_{\text{ev}}} p(d_i|\theta_i) \frac{\diff N}{\diff t_{\det} \diff \theta} (\theta_i;\Lambda) \, .
\end{aligned}
\label{eq:inhomog-poisson}
\end{equation}
Here, $\Lambda$ is the set of population parameters hyper-parameters.
$\frac{\diff N}{\diff t_{\det} \diff \theta} (\theta;\Lambda)$ is the detector frame merger rate density of \acp{BBH} conditioned on hyper-parameters $\Lambda$, this quantity is also referred to as the population model. 
Following \citet{callister_parameter-free_2023}, we use a semicolon to explicitly indicate that this is a function of $\Lambda$, not a density over $\Lambda$.
$N_{\text{exp}}(\Lambda)$ is the expected number of detections given $\Lambda$ and the \ac{GW} detector sensitivity, and is calculated using a Monte Carlo sum over $N_{\text{inj}}$ found signals injected into the data stream \citep[see][for a detailed explanation of this process]{essick_estimating_2021, essick_precision_2022}.
In this work, we have restricted our analysis to the \ac{BBH} mass distribution.
However, the method can be trivially extended to the full mass distribution of \acp{CBC} \citep[e.g.][]{fishbach_does_2020, ezquiaga_spectral_2022}.

Since the event parameters are not perfectly measured, we incorporate uncertainty to marginalize over the possible parameters associated with each event.
Practically, this is done by a Monte Carlo average over the posterior samples $\{\theta_j\}_i$ of each event $i$ and dividing out the prior used when inferring those posterior samples, $\pi_{\rm PE}(\theta)$:
\begin{equation}
\begin{aligned}
    &p(\{d\}|\Lambda) \\
    &\hspace{3mm} \propto e^{-N_{\text{exp}}(\Lambda)}\prod_i^{N_{\text{ev}}} \int 
    d\theta_i\, p(d_i|\theta_i) \frac{\diff N}{\diff t_{\det} \diff \theta} (\theta_i;\Lambda) \\
     &\hspace{3mm} \approx e^{-N_{\text{exp}}(\Lambda)}\prod_i^{N_{\text{ev}}} \frac{1}{N_{\rm samps}} \sum_{j=1}^{N_{\rm samps}} \frac{\frac{\diff N}{\diff t_{\det} \diff \theta} (\theta_{j,i};\Lambda)}{\pi_{\rm PE}(\theta_{j,i})}\,.
\end{aligned}
\label{eq:single-event-likelihood}
\end{equation}
This provides a posterior on both the compact binary population and the background cosmology when combined with a prior $p(\Lambda)$ on the population and cosmological parameters, as discussed below.
We will use the term hyper-prior to refer to $p(\Lambda)$ for the remainder of this work.

The likelihood in Equation~\eqref{eq:inhomog-poisson} is maximized when the relationship between redshift and luminosity distance makes all source-frame masses follow the same distribution.
This is the basis of the spectral siren method of measuring cosmological parameters; we can simultaneously infer the relationship between redshift and luminosity distance with the parameters of the source-frame mass distribution.
The full set of hyper-parameters therefore includes the cosmological parameters that dictate the $D_L$--$z$ relation: the local expansion rate \Ho, the present fractional energy densities of dark matter \Omm, dark energy $\Omega_\Lambda$, and radiation $\Omega_r$, and the equation of state of dark energy $w$.
In this work, we fix $\Omega_\Lambda=1-\Omega_M, \Omega_r=0$ and $w=-1$ and use uniform priors on \Ho{} and \Omm{}, corresponding to a flat $\Lambda$CDM cosmology.

Algorithmically, we evaluate the likelihood in Equation~\ref{eq:inhomog-poisson} by drawing \Ho{} and \Omm{} from their prior distributions (contained in $p(\Lambda)$), use them to define a relationship between luminosity distance and redshift, transform detector-frame masses to source-frame masses according to $m_{\det} /(1+z(D_L,H_0,\Omega_M)) = m_{\source}$, evaluate the source-frame mass distribution at these transformed values ($\diff N/\diff t_{\det} \diff \theta_i (\theta_i;\Lambda)$ for events and $N_{\text{exp}}(\Lambda)$ for injections), and then take the product of these terms to evaluate the expression in Equation~\ref{eq:inhomog-poisson}.
The full process is outlined in Appendix~\ref{ap:GP}.

%%  Wrap up with discussion of GP priors and simplifying assumptions.
\subsection{\Acl{GP}-based mass distribution}
\label{sec:model}

In this Section, we give an overview of the non-parametric mass model developed for this work.
Further details on this model, including an introduction to \acp{GP} and a discussion of their properties is given in Appendix~\ref{ap:GP}. 

With the \ac{GP} approach, the hyper-parameters describing the mass distribution are the rate at each event-level posterior sample's source frame mass, and the rate at each found injection's source frame mass.
The \ac{GP} \emph{is} $p(\Lambda)$, the prior on population parameters (except in the case of cosmological parameters, which all have uniform priors).
This is demonstrated in Figure~\ref{fig:GP example}, where the left panel shows draws from a \ac{GP}, which are prior draws for the population inference.
The smooth appearance of individual draws from the population prior, as well as the absence of overdensities at specific source frame mass values in the full prior distribution shown in Figure~\ref{fig:GP example} demonstrate that we have successfully fulfilled our goal to construct a model without predefined features in source-frame mass.
Combined with the population likelihood in Equation~\ref{eq:inhomog-poisson} the prior illustrated in the left panel of Figure~\ref{fig:GP example} gives the population posterior in the right panel.

The lack of data just below the minimum black hole mass and just above the maximum black hole mass, combined with the fact that \ac{GW} detectors are sensitive to objects at those masses, causes the \ac{GP} to learn a relatively low merger rate at the edges of the mass distribution. 
On the other hand, there is both a lack of data and little detector sensitivity at masses above $\sim100\Msun$ and below $\sim5\Msun$.
The mass distribution is therefore uninformed in this region and the \ac{GP} reverts to its prior distribution, which resembles random scatter around the mean differential merger rate.
Similar effects can be seen in other non-parametric methods \citep{edelman_cover_2023, callister_parameter-free_2023}.
% Indeed, the upper edge of the mass distribution is very informative to the \Ho{} constraint with current detections \citep{gwtc3_cosmo}.
The combination of these two effects results in what appears as an uptick in the merger rate below $\sim5\Msun$ and above $\sim100\Msun$.
However, this reversion to the prior is uninformative for the \Ho{} constraint and does not affect inference on cosmological parameters.
Additionally, the posterior on \Ho{} is distinct from its prior distribution (uniform in the range $[30\Hunits,120\Hunits]$, indicating that the data is informative despite the flexibility of the population model.

We note that other non-parametric methods may be adapted to avoid predefined features, such as fitting for the locations of their features simultaneously with the rest of the inference \citep[e.g.][]{tiwari_vamana_2021} or, in the case of splines, by using a smoothing function that allows for features to occur at arbitrary locations appropriate smoothing \citep[e.g.][]{edelman_cover_2023}. 
% Such adaptations are necessary to avoid circular inference.

The smoothness of a given \ac{GP} is determined by its kernel, which is a function that defines the covariance between input points in the \ac{GP} (in our case, two source frame mass values). 
It defines the notion of similarity between adjacent points and thereby encodes our assumptions about the smoothness of the source frame mass distribution \citep{rasmussen_gaussian_2006}.
Kernels themselves have parameters that determine their properties.
In our use case, these are one level further removed from hyper-parameters, so we adopt the terminology used in \citet{callister_parameter-free_2023} and call them ``hyper-hyper-parameters.''
We fit these hyper-hyper-parameters along with the hyper-parameters $\Lambda$ to minimize prior assumptions about the form of the mass distribution.

\begin{figure}
    \centering
    \includegraphics{figures/GP_example.pdf}
    \caption{Draws from the \acf{GP} used to model the mass distribution.
    The left panel shows prior draws from the \ac{GP} and the right panel shows the posterior draws once the population inference is performed on the simulated data.
    The posterior draws in the right panel are a subset of those used to create the 90\% credible intervals in Figure~\ref{fig:O5_GP}.}
    \label{fig:GP example}
    \script{GP_example_plot.py}
\end{figure}

\section{Results}
\label{sec:results}
In this Section we show that fitting an incorrect functional form to the mass distribution of \acp{CBC} biases the inference of cosmological parameters when using the spectral siren methodology.
We then demonstrate that our flexible model alleviates this bias without the need to know the morphology of the mass distribution \emph{a priori}.
We illustrate this explicitly by using three different models for the source-frame mass distribution to infer the cosmic expansion rate from the simulated catalog described in Section~\ref{sec:data generation} and Appendix~\ref{ap:data generation}.
The three models are as follows:
\begin{enumerate}
    \item \plp{}, which includes the true mass distribution within its hyper-prior,
    \item the \textsc{Broken Power Law} model presented in \citet{abbott_population_2021}, as we do not employ a high-mass truncation, which does not include the true mass distribution within its hyper-prior, and 
    \item the flexible, \ac{GP}-based model described in Section~\ref{sec:model}, which is able to closely approximate the morphology of the true mass distribution, along with many other morphologies.
\end{enumerate}
For all models considered in this work, we assume the redshift distribution used to generated the data, described in Equation~\ref{eq:underlying redshift dist}.
The results of each of these fits are shown in Figure~\ref{fig:O5_GP}.  
The left panel shows the inferred source-frame mass distribution for each of the considered models, and the right panel shows the corresponding posteriors on \Ho{}. 
We indicate the true underlying source mass distribution and \Ho{} value with solid black lines in each panel.

The fits presented in Figure~\ref{fig:O5_GP} are representative results from a single simulated catalog.
These provide insight into the full statistical results presented below.
In particular, it can be seen that the broken power law (orange curve) is inconsistent with the true value of $H_0$: in the run shown in Figure~\ref{fig:O5_GP}, the true value of \Ho{} is offset from the mean of the posterior by $\variable{output/BPLh0offset.txt}\sigma$.
In contrast, the \plp{} and \ac{GP}-based models (green and blue curves) are consistent with the underlying truth.
These models recover mean values of \Ho{} that are offset from the true value at $\variable{output/PLPh0offset.txt}\sigma$ and $\variable{output/nonparh0offset.txt}\sigma$, respectively. 
Additionally, the mass distribution inferred with the \ac{GP}-based model closely resembles the true, simulated distribution.
This indicates that using models that cannot accurately approximate the true mass distribution will lead to a significant systematic bias in the estimation of cosmological parameters.

This bias is not due to the need to know the morphology of the mass distribution \emph{a priori}, as the \ac{GP}-based model recovers the correct value of \Ho{} despite making minimal assumptions about the mass distribution.
% The \ac{GP}-based model does, however, obtain larger uncertainties on the inferred value of \Ho, as it has many more free parameters. 
In reality, we do not know the true functional form of the mass distribution, %so the additional statistical uncertainty introduced by non-parametric approaches may be desirable over the possible systematic errors introduced by choosing a parametric model that likely does not contain the true mass distribution within its hyper-prior.
so it may be desirable to use a non-parametric approach to avoid potential systematic errors introduced by choosing a parametric model that likely does not contain the true mass distribution within its hyper-prior.

To obtain a quantitative measure of the systematic bias introduced by mismodeling the mass distribution, we repeat the parametric analyses with 50 separate simulated catalogs of $\sim500$ events each.
We find that the broken power law model produces an overestimate of \Ho{} at greater than $1\sigma$ $\variable{output/BPL_bias_percent.txt}\%$ of the time, %whereas the \ac{GP}-based model reaches that level of bias only \result{Z}\% of the time, 
and the \plp{} model reaches the same level of bias only $\variable{output/PLP_bias_percent.txt}\%$ 
of the time.

Collectively, these results indicate that prior knowledge of the shape of the mass distribution is not required to perform an unbiased spectral siren measurement, so long as strong assumptions about the shape of the mass distribution are not made.

\subsection{Projections for Future Measurements}
Figure~\ref{fig:O5_GP} demonstrates an expected $\variable{output/nonparh0percent.txt}\%$ ($1\sigma$ uncertainties) measurement of \Ho{} after one year of \ac{O5} using the \ac{GP}-based spectral siren method, and a $\variable{output/PLPh0percent.txt}\%$ measurement with parametric spectral sirens, demonstrating comparable statistical uncertainties.
By the time of \ac{O5}, the \ac{GW} detector network is projected to detect \acp{BBH} up to redshift $\approx 3$, with most sources lying near redshift $\simeq 1.2$ \citep{chen_distance_2021}.
Additionally, next-generation detectors will be sensitive to sources up to redshift $\sim 100$.
This means that future \ac{GW} observations will be more sensitive to $H(z\gtrsim1)$ than to \Ho, and can therefore constrain several additional cosmological parameters \citep{Chen:2024gdn}.
We demonstrate this by repeating the same \ac{GP}-based spectral siren analysis while also simultaneously fitting for the local matter density, \Omm.
The result is shown in Figure~\ref{fig:O5_corner}.
We emphasize that these precise measurements over a wide range in redshift enable precision estimation of additional cosmological parameters governing $H(z)$.

We find \ac{O5} observations to be most sensitive to $H(z=\variable{output/mostsensitivez.txt})$, which is measured at $\variable{output/Hz_percent.txt}\%$.
% For comparison, the Dark Energy Spectroscopic Instrument is projected to measure $H(z=1)$ to $\sim1\%$ \citep{aghamousa_desi_2016} by 2026 \citep{schlegel_spectroscopic_2022}, 1 year before the projected start of \ac{O5} \citep{emfollow_user_guide}.
The left panel of Figure~\ref{fig:O5_corner} demonstrates a strong anti-correlation between the \Omm{} and \Ho{} posteriors, resulting in similarly informative constraints on the two parameters.
This is because \Ho{} controls the $y$-intercept of the $H(z)$ curves on the right panel, while \Omm{} informs the slope of those curves; the same measurement of $H(z\neq0)$ can be obtained by increasing the slope while decreasing the $y$-intercept, and vice versa.
Similar behavior can be observed in current measurements of the \ac{BBH} redshift distribution, which exhibits a tightening of the posterior at $z\sim0.2$ with current observations \citep{abbott_population_2023, callister_parameter-free_2023}.

Next-generation detectors will be sensitive to a larger range of redshifts \citep{et_steering_committee_einstein_2020, evans_horizon_2021}, and will therefore break the degeneracy between cosmological parameters and allow for tighter constraints on both \Omm{} and \Ho{}.
However, the small cosmological volume (and thus low number of mergers) at low redshift will generally limit the constraining power of spectral sirens at $z=0$, potentially making this method more sensitive to cosmological parameters that affect higher redshifts. % than to \Ho.
Combining spectral sirens with other methods that are sensitive to the local expansion rate, such as those that employ electromagnetic counterparts, may increase the precision of \ac{GW} standard sirens at all redshifts \citep[e.g.][]{Chen:2024gdn}.

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/O5_GP_corner.pdf}
    \caption{
    Projected constraints on multiple cosmological parameters after one year of observing at the \ac{LVK}'s design sensitivity, using the \acl{GP}-based spectral siren method.
    The right panel shows the inferred expansion history of the universe, $H(z)$.
    It will be measured most precisely at $z=\variable{output/mostsensitivez.txt}$, as can be seen by the narrowing of the inferred $H(z)$ curves there.
    The inset shows the posterior on $H(z=\variable{output/mostsensitivez.txt})$.
    Black solid lines indicate the true value of $H(z)$ in both the inset and main panel.
    The left panel shows the two-dimensional posterior on \Ho{} and \Omm, with the true value indicated by a black ``+''.
    The two parameters are strongly degenerate because of the multiple ways of measuring $z=\variable{output/mostsensitivez.txt}$.
    Spectral sirens are particularly well suited for measuring cosmological parameters that affect the Universe at $z\gtrsim0.2$. 
    }
    \label{fig:O5_corner}
    \script{nonparametric_corner.py}
\end{figure*}

% \subsubsection{BONUS: XG}
% To demonstrate the capabilities of next-generation detectors, we repeat the full analysis with \result{1000} events indicative of Cosmic Explorer's projected best-measured events within the first month alone.
% We fit the dark energy equation of state parameter, $w$, along with \Ho, and show results in Figure~\ref{fig:XG_corner}.
% We recover unbiased measurements of each parameter and find a \result{X}\% measurement of $w$ and a \result{X}\% measurement of \Ho.
% In comparison, the most recent constraints on these parameters with \result{X experiment} were \result{X}\% and \result{X}\% , respectively.
% This illustrates the unique ability of \acp{GW} to probe the high-redshift universe.
% 
% \begin{figure*}
%     \centering
%     \includegraphics[width=\textwidth]{figures/CE_GP.pdf}
%     \caption{Two-panel figure of (A) $w$, and \Ho{} corner plot and (B)$H(z)$ for CE. We can include a posterior of $H(z=z_{\text{best measured}})$ as an inset to the $H(z)$ plot.}
%     \label{fig:XG_corner}
%     \script{XG_corner.py}
% \end{figure*}

\section{Discussion}
\label{sec:discussion}

\acp{GW} are unique cosmic messengers in that they carry both redshift and distance information, making them remarkably clean probes of the Universe's expansion history calibrated directly by the theory of general relativity. 
However, the current method of determining \ac{GW} redshifts via the distribution of their source masses (i.e. spectral sirens) employs an assumption on the shape of their population, typically encapsulated by simplified parametric functions. 
This choice, often presumed to be necessary or fundamental to the method, may introduce a systematic bias to a measurement of the cosmological parameters that is otherwise appealing for its unique elegance and simplicity.
    
In this work we show that a specific choice of mass distribution is unnecessary to arrive at informative and accurate posteriors on \Ho{} and \Omm{}.
We do this by accurately measuring these cosmological parameters with a highly flexible model for the mass distribution. 
%The success of the flexible model in recovering informative and accurate posteriors on \Ho{} and \Omm{} demonstrates that there is no need to know the morphology of the \ac{CBC} mass distribution in order to constrain cosmological parameters.
This reinforces the notion that the information in the spectral siren measurement comes from the assumption that all \ac{GW} sources come from the same population, a far less stringent statement than the assumption that we understand the exact astrophysical processes which give rise to that population (i.e. the physics governing compact binary formation and evolution).

Spectral sirens are particularly useful in the context of the current Hubble tension: a disagreement between multiple methods of measuring the local expansion rate of the universe \citep{freedman_measurements_2021}.
As this tension can only be explained by non-standard physics or yet-unknown systematic uncertainties in either the cosmic distance ladder or cosmic microwave background measurements, direct and independent probes of the local expansion---such as those presented here---may help determine whether the current discrepancy represents a fundamental crack in our standard model of physics and/or cosmology.
    
Neither the mechanism from which compact binaries were formed, nor the physical processes within the mechanism, have been conclusively determined.
The true functional form of the mass distribution therefore remains elusive, meaning that systematic uncertainties arising from an incorrect choice for the form of the mass distribution are inevitable.
With current observations, these systematic effects are likely smaller than statistical uncertainties.
However, next-generation detectors will herald sufficient \ac{GW} observations to substantially decrease statistical uncertainty in these measurements; for example, \citet{pierra_study_2023} show that incorrect assumptions about the shape of the mass distribution can lead to $\sim3\sigma$ systematic biases in \Ho{} with catalogs of 2,000 events, although this bias may be an overestimate as it does not include measurement uncertainty of the \ac{GW} parameters.
Thus, non-parametric approaches may be preferable to avoid the systematic errors associated with choosing a parametric model.

In parallel with this work, \citet{magana_inprep} performed a spectral siren analysis on currently-public \ac{LVK} data using a model that employs histogram bins defined at fixed locations in source-frame mass to flexibly measure the \ac{BBH} mass distribution \citep[originally presented in][]{mandel_model-independent_2017,ray_non-parametric_2023}.
While both the method presented in this work and that of \citet{magana_inprep} employ \acp{GP}, \citet{magana_inprep} uses \acp{GP} to modulate histogram bin heights, leading to a piecewise constant function in log mass, whereas we define the \ac{GP} at each data point, constructing a smooth function with no predefined features in source-frame mass. 
% Sharp bin edges may lead to optimistic constraints on cosmological parameters, especially as such features are unlikely to exist in the true mass distribution, possibly explaining the increase in precision relative to parametric methods seen in \citet{magana_inprep}.

As demonstrated in \citet{ezquiaga_spectral_2022}, the degeneracy between an evolving mass distribution and the expansion of the universe can be broken provided that there are multiple features present in the mass distribution, and that we do not live in a fine-tuned universe where the evolutionary effects governing the \ac{CBC} mass distribution perfectly mimick the effects of cosmological redshift.
The first condition (multiple features) is known to be met in current data \citep{abbott_population_2023}, with three robust features \citep{farah_things_2023}: a maximum black hole mass and overdensities at $\sim10\Msun$ and $\sim35\Msun$.
The latter scenario---with features identically and monotonically shifting to higher masses with increasing redshift---would be astrophysically unlikely as the locations of features in the mass distribution are each thought to be governed by fundamentally different physical processes \citep{mapelli_binary_2020}.
The non-parametric methods presented here will allow for arbitrary redshift evolution.
Additionally, since \aclp{GP} naturally scale to multiple data dimensions \citep{rasmussen_gaussian_2006}, the method presented here can easily be generalized to fit the redshift dependence of the mass distribution. 
Future work will extend the method developed here to mass distributions that are allowed to evolve with redshift.

Because \ac{GW} observations are the only data input to spectral sirens, they are uniquely positioned to probe the expansion history of the universe over a wide range of cosmological redshift, rather than just the local expansion \Ho.
We have shown this by simultaneously measuring \Omm{} and \Ho{}; the method can be trivially expanded to constrain additional cosmological parameters that govern $H(z)$, such as the dark energy equation of state parameter, $w$. 
We find that for \acl{O5}, spectral sirens will be most constraining at $z=\variable{output/mostsensitivez.txt}$.
This redshift is larger than the expected redshifts of detectable electromagnetic counterparts of binary neutron star mergers~\citep{kiendrebeogo_updated_2023}, implying that upgrades to current \ac{GW} detectors will allow the spectral siren method to probe $H(z)$ at otherwise unexplored distances by \acp{GW}. 
Proposed next-generation \ac{GW} detectors such as Cosmic Explorer and Einstein Telescope will be sensitive to \acp{CBC} across cosmic time (out to $z\sim100$)~\citep{et_steering_committee_einstein_2020, evans_horizon_2021}.
Future cosmological surveys, such as those enabled by the Nancy Grace Roman Space Telescope and the Vera Rubin Observatory, are expected to be able to precisely measure $H(z)$ to $z\sim3$ \citep{spergel_wide-field_2015}, making the spectral siren method uniquely positioned to measure the expansion of the universe at high redshift.
When combined with bright and dark siren methods, the low-redshift expansion history will also be well-constrained \citep{Chen:2024gdn}.
Sensitivity to high redshifts is a feature of the spectral siren method in general, and non-parametric methods such as the one presented here will be imperative to avoid systematic biases in spectral siren cosmology. 

\begin{acknowledgments}
    The authors thank Reed Essick, Ben Farr, Maya Fishbach, Utkarsh Mali, and Colm Talbot for helpful conversations. 
    %Amanda
    A.M.F. is supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-1746045.
    %Tom
    %Jose
    J.M.E. is supported by the European Union’s Horizon 2020 research and innovation program under the Marie Sklodowska-Curie grant agreement No. 847523 INTERACTIONS, and by VILLUM FONDEN (grant no. 53101 and 37766). 
    %Mike
    M.Z. gratefully acknowledges funding from the Brinson Foundation in support of astrophysics research at the Adler Planetarium.
    %Daniel
    D.E.H is supported by NSF grants AST-2006645 and PHY-2110507, as well as by the Kavli Institute for Cosmological Physics through an endowment from the Kavli Foundation and its founder Fred Kavli.
    %Cluster
    The Tycho supercomputer hosted at the SCIENCE HPC center at the University of Copenhagen was used for supporting this work.
    %LIGO
    This material is based upon work supported by NSF's LIGO Laboratory which is a major facility fully funded by the National Science Foundation.
\end{acknowledgments}

\software{\texttt{numpyro} \citep{phan_composable_2019,bingham_pyro_2019}, \texttt{tinygp} \citep{foreman-mackey_tinygp_2021}, \texttt{arviz} \citep{kumar_arviz_2019}, \texttt{jax}, \showyourwork \citep{Luger2021}
          }

\bibliography{bib}
\appendix
\section{Details of data simulation}
\label{ap:data generation}
The exact form of the injected population is
\begin{equation}
\label{eq:underlying population}
    \frac{\diff N}{\diff m_1 \diff z} \propto p(m_1|\bar{\Lambda}_m) p(z|\bar{\Lambda}_z, H_0, \Omega_M),
\end{equation}
where 
\begin{align}
    p(m_1,m_2|\bar{\Lambda}_m) &\propto \mathcal{S}(m_{\min},m_{\max})
    \left( f_{\text{peak}}e^{-\frac{1}{2}(\frac{m_1-\mu}{\sigma})^2}\mathcal{N}_{\text{g}} +
    (1-f_{\text{peak}})m_1^{\alpha}\mathcal{N}_{\text{pl}} \right) ,
\label{eq:underlying mass dist}
\end{align}
\begin{equation}
    p(z|H_0, \Omega_M) \propto \frac{\diff V_C}{\diff z} \frac{1}{1+z} \frac{(1+z)^\alpha}{1+\left(\frac{1+z}{1+z_p}\right)^{\alpha+\beta}}.
    \label{eq:underlying redshift dist}
\end{equation}
Here, $V_C(H_0, \Omega_M)$ is the comoving volume for given cosmological parameters \Ho{} and \Omm{}, and $\bar{\Lambda}_m = \{\alpha, m_{\min}, m_{\max}, \mu, \sigma, f_{\text{peak}}\}$ are the (hyper-)parameters describing the power law in primary mass, minimum and maximum black hole mass, Gaussian peak location and width, and fraction of events in the Gaussian peak, respectively.
$\mathcal{S}$ is a smoothing function at low and high masses, and $\mathcal{N}_{\text{pl}}$ and $\mathcal{N}_{\text{g}}$ are the normalizations between  $m_{\min}$ and $m_{\max}$ for the power law component and truncated Gaussian component, respectively.
$\bar{\Lambda}_z = \{z_p,\alpha_z,\beta_z\}$ are the parameters governing the peak of the redshift distribution, low-$z$ power law slope, and high-$z$ power law slope.
When generating the simulated events, we have fixed $\alpha=-2.7$, $m_{\max}=78\Msun$, $m_{\min}=10~\Msun$, $\mu=30~\Msun$, $\sigma=7.0~\Msun$, $f_{\text{peak}}=0.05$, $z_p=2.4$, $\alpha_z=1.0$, and $\beta_z=3.4$.
These choices correspond to the maximum \emph{a posteriori} values obtained by an analysis of GWTC-3 data using the \plp{} model \citep{abbott_population_2023}.
For simplicity, we additionally assume that the population has equal masses, $m_1=m_2$, and thus, $\theta = \{m_1,z\}$.
We consistently apply this assumption to the data generation process and the population inference.
We do not fit for or simulate spins, as they do not redshift and hence do not carry additional cosmological information, and additionally neglect secondary masses.

We use cosmological parameters \Ho$=\variable{output/H0_FID.txt}\Hunits$, \Omm$=0.3$, and $\Omega_\Lambda=1-$\Omm, consistent with those found by \citet{planck_collaboration_planck_2016}.
We emphasize, however, that the choice of cosmological parameters for data generation is arbitrary and does not impact the results, since we are concerned only with the ability of our method to recover the injected values.
Throughout the data generation and inference, we use the approximations presented in \citet{adachi_analytical_2012} to efficiently convert between $d_L$ and $z$ for a given set of cosmological parameters \Omm{} and \Ho.

We do not include neutron stars in our simulation set, as their contribution to the spectral siren measurement is expected to be subdominant in \ac{O5}.
However, if a lower mass gap between the heaviest neutron stars and lightest black holes exists, it will provide an additional feature with which to inform the measurement, and will be the most informative feature for spectral siren measurements with next-generation detectors \citep{ezquiaga_spectral_2022}.

After passing the simulated events through projected detector selection effects, the resulting catalog has $\variable{output/num_found_events.txt}$ events, consistent with the numbers projected for \ac{O5} by \citet{kiendrebeogo_updated_2023}.
We use the software package \texttt{GWMockCat} \citep{farah_things_2023} to simulate posterior samples for these events with measurement uncertainties typical of those expected from \ac{O5} detectors.
\texttt{GWMockCat} also simulates a set of software injections, which we use to estimate selection effects in the inference.
To determine the detectability of both injections and simulated events in O5, we use the projected \ac{O5} LIGO power spectral density \citep{obsscen_noise_curves,abbott_prospects_2020} for a single detector to calculate observed signal-to-noise ratios $\rho_{\text{obs}}$, and we consider events and injections with a single-detector SNR $\rho_{\text{obs}}>8$ to be detectable. 
The full procedure for this mock data generation process is described in \citet{fishbach_where_2017, farah_things_2023, essick_ensuring_2024}.

\section{\Acl{GP}-based mass distribution}
\label{ap:GP}

In this Section, we discuss the properties of the \ac{GP}-based mass distribution and describe our modeling choices in more detail. % we also show how it is able to recover a wide range of morphologies and is not tuned to the PLP mass distribution.

Practically, the difference in the inference of the population when using a \ac{GP} versus other modeling choices is that the population model ($\diff N/\diff t_{\det} \diff \theta_i (\theta_i;\Lambda)$ in Equation~\ref{eq:inhomog-poisson}) is determined directly by a realization of the \ac{GP}, rather than by a handful of hyper-parameters $\Lambda$ and evaluated on an analytical function.
In other words, when using parametric models, $\diff N/\diff t_{\det} \diff \theta_i (\theta_i;\Lambda)$ is calculated by evaluating a specific functional form described by a small set of hyper-parameters. 
With the \ac{GP} approach, the hyper-parameters describing the mass distribution are the rate at each event-level posterior sample's source frame mass, and the rate at each found injection's source frame mass.
The \ac{GP} \emph{is} $p(\Lambda)$, the prior on population parameters (except in the case of cosmological parameters, which all have uniform priors).

Because the \ac{GP} is defined only at specific data points, we have $N_{\text{ev}}M + N_{\text{inj}}$ mass hyper-parameters, where $M$ is the number of posterior samples per event and $N_{\text{inj}}$ is the number of injections used to calculate the selection function~\citep[see e.g.][]{vitale_inferring_2020,talbot,essick_estimating_2021}.
In this way, our \ac{GP}-based mass distribution is similar to the autoregressive population models used in~\citet{callister_parameter-free_2023}.
Indeed, an autoregressive process is a \ac{GP} with a specific choice of kernel.

The kernel is a function that defines the covariance between input points in the \ac{GP} (in our case, two source frame mass values). 
It defines the notion of similarity between adjacent points and thereby encodes our assumptions about the smoothness of the source frame mass distribution \citep{rasmussen_gaussian_2006}.
We use a Mat\'ern kernel \citep{handcock_bayesian_1993, stein_interpolation_1999} with $\nu = 5/2$, but have repeated the analysis with $\nu=3/2$ and $\infty$, finding little impact on the results, except that the $\nu=\infty$ case (also called the squared exponential kernel) produces a slightly more jagged mass distribution.
In addition to the mean, Mat\'ern kernels have two parameters that determine their properties: a length scale $l$ and a variance $s$.
In our use case, these are one level further removed from hyper-parameters, so we adopt the terminology used in \citet{callister_parameter-free_2023} and call them ``hyper-hyper-parameters.''
We fit these hyper-hyper-parameters along with the hyper-parameters $\Lambda$ to minimize prior assumptions about the form of the mass distribution.
We use penalized-complexity priors on the hyper-hyper-parameters to enforce that the model does not create small-scale structure uninformed by data, thereby avoiding over-fitting \citep{simpson_penalising_2017,simpson_garcpas_2022}. 
Explicitly, the priors on $l$ and $s$ are Fr\'echet and Gamma distributions, respectively, and are defined to have less than 5\% support for correlation lengths smaller than the average spacing between event-level posterior means.

The time to evaluate a \ac{GP} is notorious for scaling as the cube of the number of data points, making \acp{GP} unwieldy with large data sets, such as the $\mathcal{O}(10^9)$ posterior samples and software injections expected for \ac{O5}.
We therefore make two approximations to a full \ac{GP} to increase computational efficiency.
First, for each likelihood evaluation, we evaluate a full \ac{GP} on a regular grid between $0.1\Msun$ and $250\Msun$ and then interpolate it at each data point.
Second, we use the quasi-separability of Mat\'ern kernels to analytically perform the transformation between covariance matrix and \ac{GP} draw.
This second step is done using the \texttt{QuasisepSolver} module \citep{foreman-mackey_fast_2017} in the \texttt{tinygp} code base \citep{foreman-mackey_tinygp_2021}, and requires data to be sortable (i.e. one-dimensional).

Algorithmically, each posterior evaluation contains the following steps: \variable{output/priors_placeholder.txt}
\begin{enumerate}
\script{nonparametric_inference.py}
    \item Draw cosmological parameters \Ho{} and \Omm{} from uniform prior distributions.
    \item Convert the luminosity distances and detector-frame masses of each event posterior sample to redshifts and source-frame masses according to the cosmology specified by step 1.
    \item Draw hyper-hyper-parameters $l$ and $s$ from the penalized-complexity priors described above.
    \item Draw a single \ac{GP} realization with a kernel defined by $l$ and $s$.
    This is defined on a regular grid of source-frame masses and evaluated using the \texttt{QuasisepSolver} in \texttt{tinygp}.
    \item Interpolate the \ac{GP} at each event posterior sample and injection source-frame mass (from step 3).
    \item Calculate the population likelihood according to Equation~\ref{eq:inhomog-poisson}.
\end{enumerate}
% TODO: \jme{[comment: is there a way to summarize this list in a simple diagram?]}
We perform these steps within \texttt{numpyro} \citep{bingham_pyro_2019,phan_composable_2019}, sampling the posterior using the no-u-turn sampler for Hamiltonian Monte Carlo \citep{hoffman_no-u-turn_2011}. 
This can be seen explicitly in the source code accompanying this paper, in the \texttt{scripts/priors.py} \variable{output/priors_placeholder.txt}script.

% \begin{itemize}
%     \item fit of GP to various mass dist morphologies, showing how flexible it is (fixing H0)
% \end{itemize}

% \section{Old}
% Old tex that we may end up needing.

% \begin{table}[]
%     \centering
%     \begin{tabular}{c|c c}
%          Model & $\sigma_{H_0}$ [km/s/Mpc] & bias [km/s/Mpc]\\
%          \hline
%          & 
%     \end{tabular}
%     \caption{Performance of various mass distribution models used for measuring the Hubble constant, \Ho.
%     We consider the correct parametric model, a deliberately incorrect parametric model, and the non-parametric, \ac{GP}-based model presented in this work.
%     Bias is defined as the number of standard deviations between the true injected value of \Ho and the recovered posterior mean. 
%     The parametric models yield more precise constraints on \Ho{}, as shown by smaller standard deviations ($\sigma_{H_0}$), but the incorrect parametric model is less accurate than the non-parametric model.
%     In reality, it is impossible to know the true functional form of the mass distribution, so the additional statistical uncertainty introduced by non-parametric approaches may be desirable over the systematic errors associated with choosing a parametric model.
%     }
%     \label{tab:bias}
% \end{table}

% \subsection{Option 2: GP only}
% We fit the non-parametric population model described in Section~\ref{sec:model} to a simulated \ac{GW} catalog of $\variable{output/num_found_events.txt}$ \ac{GW} events from an underlying mass distribution described by the \plp{} model, with hyperparameters consistent with those found in \citet{abbott_population_2023}.
% This simulated catalog is designed to be representative of the \ac{GW}  transient catalog after \ac{O5}.
% The details of the data simulation are described in Appendix~\ref{ap:data generation}.

% The resulting inferred mass distribution is shown in Figure~\ref{fig:O5_GP}, along with the corresponding posterior on \Ho.
% The inferred mass distribution closely resembles the true, simulated distribution, and the injected value of \Ho{} ($\variable{output/H0_FID.txt}\Hunits$) is consistent with its inferred posterior (\variable{output/nonparh0CI.txt}$\Hunits$).
% At very high and very low masses, there is both a lack of data and little detector sensitivity.
% The mass distribution is therefore uninformed in this region and the \ac{GP} reverts to its prior distribution, which resembles random scatter around the mean differential merger rate.
% Similar effects can be seen in other non-parametric methods \citep{edelman_cover_2023, callister_parameter-free_2023}.
% On the other hand, the lack of data just below the minimum black hole mass and just above the maximum black hole mass, combined with the fact that \ac{GW} detectors are sensitive to objects in that mass range causes the GP to learn a relatively low merger rate at the edges of the mass distribution.
% Indeed, these features are very informative to the \Ho{} constraint \citep{gwtc3_cosmo}.
% The combination of these two effects results in what appears as an uptick in the merger rate at very low and very high masses, but these features are uninformative and do not affect inference on cosmological parameters.
% Additionally, the posterior on \Ho{} is distinct from its prior distribution (uniform in the range $[30\Hunits,120\Hunits]$, indicating that the data is informative despite the flexibility of the population model.

% \subsection{Old intro text}
% Perhaps because of the analogy to electromagnetic spectra, in which the locations of source-frame spectral features are often known from first principles, it is commonly presumed that the exact shape of the mass distribution must be known \emph{a priori} to perform a spectral siren redshift measurement.
% This would certainly be problematic, as mismodeling of the specific features would hinder the accuracy of the method and introduce biases in the cosmological inference \citep{Mukherjee:2021rtw,mastrogiovanni_importance_2021,pierra_study_2023}.
% Such systematic bias is illustrated in Figure~\ref{fig:O5_GP}, where we show the result of fitting simulated data with a model that has the true mass distribution contained within its prior and one that does not. 
% The latter does not accurately infer the true value of \Ho{}, whereas the former does.

% This is particularly troubling in light of the fact that there remains much uncertainty over the cause, location, and robustness of currently-identified features in the \ac{GW} source mass distribution.
% While several features have been identified in the current data \citep{tiwari_exploring_2022,edelman_aint_2022, abbott_population_2023,edelman_cover_2023}, including three overdensities, two underdensities, a maximum and minimum black hole mass, only three of these are statistically robust \citep{farah_things_2023}.
% Additionally, the morphology of the mass distribution is a result of the interplay between several complex physical processes pertaining to massive stars, such as binary stellar evolution, pair instability, globular cluster dynamics, and stellar winds, each of which has large theoretical uncertainties \citep[e.g.][]{ zevin_constraining_2017, mapelli_binary_2020,marchant_evolution_2023}. 
% These large theoretical uncertainties mean that accurate predictions for the shape of the \ac{GW} source mass distribution are a considerable challenge.
%If such \emph{a priori} knowledge of the mass distribution's morphology were requisite for a spectral siren method, the effectiveness of such a measurement would be significantly hampered.

% However, the information in the spectral siren measurement comes solely from the assumption that all \acp{CBC} follow the same mass distribution.\footnote{More precisely, the spectral siren method is also valid if \acp{CBC} have different mass distributions at different redshifts, so long as the evolution of the mass distribution does not exactly mimic cosmology, and the model for the mass distribution allows for evolution \citep{ezquiaga_spectral_2022}. }
% Therefore the location, shape, and existence of all features in the mass distribution can be inferred simultaneously with $H(z)$. 

% synonyms

% a parametric model of the same form as the true simulated distribution (\plp) 
% a model that cannot accurately represent the true shape of the mass distribution (BPL)


\end{document}
